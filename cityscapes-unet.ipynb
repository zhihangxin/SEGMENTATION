{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('../input/city-scape/leftimg8bit_trainvaltest/leftImg8bit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.io.gfile.glob(\n",
    "    \"./leftimg8bit_trainvaltest/leftImg8bit/train/*/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = tf.io.gfile.glob(\n",
    "    \"./gtfine_trainvaltest/gtFine/train/*/*_gtFine_labelIds.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.sort(key=lambda x:x.split('train/')[-1].split('_leftImg8bit.png')[0])\n",
    "annotations.sort(key=lambda x:x.split('train/')[-1].split('_gtFine_labelIds.png')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[1005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.io.read_file(annotations[536])\n",
    "img = tf.image.decode_png(img, channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = len(images)\n",
    "len(images), len(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2019)\n",
    "index = np.random.permutation(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = np.array(annotations)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = tf.data.Dataset.from_tensor_slices((images, anno))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val = tf.io.gfile.glob(\n",
    "    \"./leftimg8bit_trainvaltest/leftImg8bit/val/*/*.png\")\n",
    "annotations_val = tf.io.gfile.glob(\n",
    "    \"./gtfine_trainvaltest/gtFine/val/*/*_gtFine_labelIds.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_count = len(images_val)\n",
    "len(images_val), len(annotations_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val = tf.data.Dataset.from_tensor_slices((images_val, annotations_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_png_label(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "    input_image = tf.cast(input_image, tf.float32)/127.5 - 1\n",
    "    input_mask = tf.cast(input_mask, tf.int32)\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(img, mask):\n",
    "    concat_img = tf.concat([img, mask], axis=-1)\n",
    "    concat_img = tf.image.resize(concat_img, (280, 280),\n",
    "                                 method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    crop_img = tf.image.random_crop(concat_img, [256, 256, 4])\n",
    "    return crop_img[ :, :, :3], crop_img[ :, :, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(input_image_path, input_mask_path):\n",
    "    input_image = read_png(input_image_path)\n",
    "    input_mask = read_png_label(input_mask_path)\n",
    "    \n",
    "    input_image, input_mask = random_crop(input_image, input_mask)\n",
    "#    input_image = tf.image.resize(input_image, [256, 256])\n",
    "#    input_mask = tf.image.resize(input_mask, [256, 256])\n",
    "    \n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_val(input_image_path, input_mask_path):\n",
    "    input_image = read_png(input_image_path)\n",
    "    input_mask = read_png_label(input_mask_path)\n",
    "    input_image = tf.image.resize(input_image, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    input_mask = tf.image.resize(input_mask, (IMG_HEIGHT, IMG_WIDTH))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE = 8 * tpu_strategy.num_replicas_in_sync\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = 300\n",
    "STEPS_PER_EPOCH = train_count // BATCH_SIZE\n",
    "VALIDATION_STEPS = val_count // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.map(load_image_train, num_parallel_calls=AUTO)\n",
    "dataset_val = dataset_val.map(load_image_val, num_parallel_calls=AUTO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.cache().repeat().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(AUTO)\n",
    "dataset_val = dataset_val.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ignore_order = tf.data.Options()\n",
    "ignore_order.experimental_deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for img, musk in train_dataset.take(1):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(img[0]))\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(musk[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(256, 256, 3))\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(inputs)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)     #  256*256*64\n",
    "    \n",
    "    x1 = tf.keras.layers.MaxPooling2D(padding='same')(x)   # 128*128*64\n",
    "    \n",
    "    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)     \n",
    "    x1 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x1)\n",
    "    x1 = tf.keras.layers.BatchNormalization()(x1)     #  128*128*128\n",
    "    \n",
    "    x2 = tf.keras.layers.MaxPooling2D(padding='same')(x1)   # 64*64*128\n",
    "    \n",
    "    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)     \n",
    "    x2 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x2)\n",
    "    x2 = tf.keras.layers.BatchNormalization()(x2)     #  64*64*256\n",
    "    \n",
    "    x3 = tf.keras.layers.MaxPooling2D(padding='same')(x2)   # 32*32*256\n",
    "    \n",
    "    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)     \n",
    "    x3 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x3)\n",
    "    x3 = tf.keras.layers.BatchNormalization()(x3)     #  32*32*512\n",
    "    \n",
    "    x4 = tf.keras.layers.MaxPooling2D(padding='same')(x3)   # 16*16*512\n",
    "    \n",
    "    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n",
    "    x4 = tf.keras.layers.BatchNormalization()(x4)     \n",
    "    x4 = tf.keras.layers.Conv2D(1024, 3, padding='same', activation='relu')(x4)\n",
    "    x4 = tf.keras.layers.BatchNormalization()(x4)     #  16*16*1024\n",
    "    \n",
    "    #  up sampling\n",
    "    \n",
    "    x5 = tf.keras.layers.Conv2DTranspose(512, 2, strides=2,\n",
    "                                         padding='same', activation='relu')(x4) \n",
    "    x5 = tf.keras.layers.BatchNormalization()(x5)     #  32*32*512\n",
    "    \n",
    "    x6 = tf.concat([x3, x5], axis=-1)  #  32*32*1024\n",
    "    \n",
    "    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n",
    "    x6 = tf.keras.layers.BatchNormalization()(x6)     \n",
    "    x6 = tf.keras.layers.Conv2D(512, 3, padding='same', activation='relu')(x6)\n",
    "    x6 = tf.keras.layers.BatchNormalization()(x6)     #  32*32*512\n",
    "    \n",
    "    x7 = tf.keras.layers.Conv2DTranspose(256, 2, strides=2,\n",
    "                                         padding='same', activation='relu')(x6) \n",
    "    x7 = tf.keras.layers.BatchNormalization()(x7)     #  64*64*256\n",
    "    \n",
    "    x8 = tf.concat([x2, x7], axis=-1)  #  64*64*512\n",
    "    \n",
    "    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n",
    "    x8 = tf.keras.layers.BatchNormalization()(x8)     \n",
    "    x8 = tf.keras.layers.Conv2D(256, 3, padding='same', activation='relu')(x8)\n",
    "    x8 = tf.keras.layers.BatchNormalization()(x8)     #  64*64*256\n",
    "    \n",
    "    x9 = tf.keras.layers.Conv2DTranspose(128, 2, strides=2,\n",
    "                                         padding='same', activation='relu')(x8) \n",
    "    x9 = tf.keras.layers.BatchNormalization()(x9)     #  128*128*128\n",
    "    \n",
    "    x10 = tf.concat([x1, x9], axis=-1)  #  128*128*256\n",
    "    \n",
    "    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n",
    "    x10 = tf.keras.layers.BatchNormalization()(x10)     \n",
    "    x10 = tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu')(x10)\n",
    "    x10 = tf.keras.layers.BatchNormalization()(x10)     #  128*128*128\n",
    "    \n",
    "    x11 = tf.keras.layers.Conv2DTranspose(64, 2, strides=2,\n",
    "                                         padding='same', activation='relu')(x10) \n",
    "    x11 = tf.keras.layers.BatchNormalization()(x11)     #  256*256*64\n",
    "    \n",
    "    x12 = tf.concat([x, x11], axis=-1)  #  256*256*128\n",
    "    \n",
    "    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n",
    "    x12 = tf.keras.layers.BatchNormalization()(x12)     \n",
    "    x12 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')(x12)\n",
    "    x12 = tf.keras.layers.BatchNormalization()(x12)     #  256*256*64\n",
    "    \n",
    "    output = tf.keras.layers.Conv2D(34, 1, padding='same', activation='softmax')(x12)\n",
    "    #  256*256*34\n",
    "    return tf.keras.Model(inputs=inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanIoU(tf.keras.metrics.MeanIoU):\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.argmax(y_pred, axis=-1)\n",
    "        return super().__call__(y_true, y_pred, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['acc', MeanIoU(num_classes=34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset_train, \n",
    "                    epochs=EPOCHS,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    validation_steps=VALIDATION_STEPS,\n",
    "                    validation_data=dataset_val,)\n",
    "#                    callbacks=[lr_callback],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "#plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataset_val.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num):\n",
    "        plt.subplot(num, 3, i*num+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n",
    "        plt.subplot(num, 3, i*num+2)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n",
    "        plt.subplot(num, 3, i*num+3)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in dataset_train.take(1):\n",
    "    pred_mask = model.predict(image)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(num):\n",
    "        plt.subplot(num, 3, i*num+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(image[i]))\n",
    "        plt.subplot(num, 3, i*num+2)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(mask[i]))\n",
    "        plt.subplot(num, 3, i*num+3)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(pred_mask[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('unet_v7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
